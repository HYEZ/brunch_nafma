{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import glob\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./res/writer_user_sentences_keyword.txt')\n",
    "\n",
    "words = []\n",
    "for f in files:\n",
    "    file = open(f)\n",
    "    words.append(file.read())\n",
    "    file.close()\n",
    "\n",
    "words = list(chain.from_iterable(words))\n",
    "words = ''.join(words)[:-1]\n",
    "sentences = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['user'] = sentences_df[0].apply(lambda x : x.split()[0])\n",
    "sentences_df['words'] = sentences_df[0].apply(lambda x : ' '.join(x.split()[1:]))\n",
    "sentences_df['words_list']  = sentences_df[0].apply(lambda x : x.split())\n",
    "sentences_df['words_num'] = sentences_df[0].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sum(sentences_df.head(3000)['words_list'].tolist(), [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3842570"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df['words_num'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df_indexed = sentences_df.reset_index().set_index('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 730], ('여행', 62927), ('사랑', 57557), ('에세이', 51717), ('영화', 44162)]\n",
      "Sample data [[1, 161, 1710, 36, 52369, 2590, 5437, 399, 52370, 135, 922, 74, 18133, 786, 2137, 13722, 7154, 1007, 36, 3120, 134, 380, 495, 52371, 10354, 52372, 399, 36, 7497, 2041, 52373, 140, 1278, 52374, 31790, 1391, 4, 16325, 547, 153, 164, 38726, 52375, 2124, 255, 4988, 390, 23, 36, 1223, 127, 10355, 1389, 710, 25, 860, 357, 16326, 530, 3703, 2830, 24653, 7155, 1694, 844, 108, 605, 288, 6, 52376, 10633, 52377, 45, 2, 140, 27586, 6160, 7154, 637, 1007, 1663, 14903, 3551, 10115, 52378, 19321, 96, 31791, 52379, 44, 81, 124, 27587, 860, 488, 6483, 53, 47, 31792, 36, 357, 111, 561, 357, 4689, 34, 96, 3411, 99, 795, 1601, 4690, 111, 146, 50, 92, 25, 3474, 3066, 27588, 126, 725, 36, 24654, 36, 147, 36, 2020, 45, 7643, 25, 7266, 10941, 2041, 36, 6, 128, 101, 284, 1126, 242, 495, 110, 4841, 52380, 52381, 229, 2324, 161, 1, 192, 15555, 17191, 12799, 51, 124, 1300, 496, 10356, 120, 8362, 52382, 52383, 18134, 31793, 8362, 10357, 10356, 3, 9244, 1300, 11249, 630, 9245, 96, 473, 27589, 3106, 128, 357, 637, 710, 399, 1, 3861, 7156, 23, 4654, 243, 399, 2349, 6245, 6484, 624, 1144, 974, 2573, 51, 20748, 1, 284, 350, 59, 14904, 1127, 121, 164, 132, 36, 6865, 141, 744, 684, 68, 153, 52384, 13723, 11981, 547, 84, 899, 736, 10116, 14275, 127, 45, 4989, 4474, 126, 56, 1174, 256, 38727, 40, 1287, 2161, 38728, 1, 5083, 621, 52385, 1300, 10356, 103, 406, 299, 36, 2041, 52386, 52387, 38729, 36, 110, 31794, 10941, 17192, 2, 18, 66, 52388, 52389, 101, 104, 7049, 379, 1178, 284, 495, 110, 52390, 1895, 36, 2, 36, 645, 22527, 1150, 17193, 4389, 5928, 419, 1300, 531, 40, 121, 3066, 54, 120, 83, 23, 631, 33, 592, 413, 13724, 3385, 52391, 12800, 7154, 399, 299, 11982, 299, 11982, 1224, 299, 11982, 586, 12393, 14275, 12801, 99, 2697, 18, 52392, 1472, 288, 6086, 508, 17194, 15, 18, 185, 52393, 9075, 1147, 646, 991, 1508, 520, 9076, 7157, 36, 399, 6866, 52394, 52395, 1300, 158, 7783, 36, 1300, 137, 83, 3386, 3323, 9, 2, 19322, 110, 38730, 605, 24655, 38731, 1, 161, 52396, 357, 7784, 24656, 7158, 266, 7267, 56, 357, 385, 4, 615, 1521, 2, 1521, 7049, 1, 141, 97, 9880, 2056, 110, 1217, 413, 5375, 6, 2, 387, 11612, 96, 1171, 18134, 357, 284, 547, 357, 117, 34, 19, 60, 1319, 47, 52397, 52398, 74, 357, 344, 288, 19323, 1300, 27590, 120, 17195, 19324, 357, 13722, 7154, 637, 6322, 52399, 120, 16326, 4088, 38732, 15, 1763, 31795, 24657, 357, 27591, 36, 547, 5609, 1300, 25, 7268, 630, 1148, 357, 833, 993, 68, 201, 699, 835, 16, 40, 18135, 6246, 287, 52400, 36, 31796, 13723, 4390, 357, 1459, 36, 4989, 357, 31797, 2747, 105, 12802, 749, 14276, 255, 165, 11982, 1993, 292, 11250, 16327, 52401, 125, 36, 45, 719, 1164, 1078, 96, 7940, 31798, 1492, 3207, 279, 66, 560, 15556, 2, 18, 1895, 38733, 3736, 515, 102, 48, 184, 1503, 128, 357, 153, 5041, 1517, 12, 52402, 15557, 3261, 235, 926, 1319, 293, 11613, 645, 111, 844, 399, 1402, 52403, 24658, 52404, 4391, 1535, 96, 563, 4, 11982, 1819, 299, 1224, 1819, 17196, 36, 110, 267, 2478, 311, 1126, 27592, 6965, 3066, 54, 120, 2257, 36, 96, 1122, 153, 1717, 158, 1096, 189, 2284, 66, 11983, 111, 24659, 3506, 8693, 134, 4988, 69, 7050, 710, 3208, 312, 357, 5498, 52405, 52406, 52407, 52408, 25, 357, 36, 263, 3997, 52409, 2350, 18136, 51, 12394, 52410, 406, 27587, 18137, 52411, 1033, 399, 4655, 1819, 165, 20749, 2, 101, 1294, 2, 104, 101, 31799, 159, 134, 36, 12803, 8362, 40, 35, 1706, 1300, 10356, 7784, 3531, 84, 3084, 52412, 584, 371, 24660, 27593, 52413, 16326, 52414, 96, 3247, 548, 1985, 908, 52415, 520, 1141, 25, 18138, 828, 54, 23, 36, 16328, 282, 24661, 1819, 3828, 169, 25, 15555, 96, 6966, 53, 357, 1300, 53, 1300, 34, 677, 137, 66, 825, 13725, 36, 5929, 6967, 14905, 38734, 399, 737, 588, 6247, 6754, 80, 6968, 2591, 3571, 84, 76, 52416, 36, 7051, 6, 3106, 547, 128, 38735, 7785, 399, 1683, 9881, 380, 14277, 36, 923, 2351, 36, 3737, 36, 14906, 69, 25, 508, 9452, 1949, 710, 38736, 5245, 255, 165, 3324, 640, 6087, 13726, 148, 28, 1717, 496, 87, 27594, 123, 52417, 624, 82, 1635, 14278, 130, 96, 66, 88, 638, 25, 860, 24662, 27595, 284, 6557, 4392, 99, 31800, 2025, 52418, 12395, 52419, 52420, 10358, 3247, 99, 4656, 36, 24663, 117, 330, 6161, 22528, 8534, 36, 52421, 394, 5930, 23, 495, 110, 19321, 52422, 24662, 52423, 52424, 586, 48, 9246, 151, 7052, 3106, 128, 2297, 103, 6969, 110, 6558, 105, 97, 148, 38737, 1826, 27596, 66, 1949, 1, 133, 4990, 1181, 27595, 516, 1370, 1, 9077, 73, 547, 23, 4, 4990, 1521, 97, 105, 16329, 39, 1521, 2057, 24664, 1300, 508, 128, 1536, 279, 34, 38738, 380, 398, 22529, 16330, 164, 1122, 1127, 2013, 36, 1521, 52425, 14907, 547, 24657, 357, 464, 19325, 3363, 16331, 11984, 1953, 1949, 105, 1, 384, 80, 630, 1223, 1, 125, 2574, 49, 3027, 6004, 4577, 380, 23, 148, 173, 87, 1949, 1609, 3829, 24665, 357, 1300, 36, 110, 413, 1954, 710, 12396, 14908, 28, 31801, 6088, 36, 15558, 110, 96, 9660, 58, 858, 1905, 569, 313, 96, 8209, 315, 1, 4438, 25, 38739, 710, 96, 36, 38740, 52426, 25, 860, 18, 18139, 163, 45, 96, 398, 44, 48, 270, 11251, 357, 27597, 899, 120, 4792, 1, 11614, 321, 5437, 406, 121, 4238, 1264, 154, 284, 52427, 4475, 7497, 52428, 144, 563, 212, 873, 20750, 5930, 53, 24666, 1150, 99, 1300, 103, 99, 1482, 11, 38741, 112, 479, 84, 31802, 9, 894, 10942, 38742, 452, 34, 357, 134, 36, 2, 110, 1402, 357, 229, 1869, 319, 73, 2026, 1827, 3282, 36, 844, 1694, 110, 1391, 60, 31803, 59, 120, 147, 7385, 31804, 547, 17197, 9661, 52429, 860, 25, 495, 52430, 110, 83, 14909, 80, 10356, 1300, 1262, 1695, 9662, 6755, 275, 7498, 40, 36, 1391, 243, 856, 189, 1453, 517, 35, 2147, 9247, 10117, 399, 7786, 13727, 40, 137, 290, 316, 110, 6967, 2373, 563, 474, 36, 10356, 1300, 1960, 92, 50, 638, 8868, 161, 1495, 25, 27598, 56, 140, 899, 4356, 4, 646, 2, 10356, 496, 1300, 646, 1521, 16330, 1999, 11252, 2406, 38743, 497, 66, 31805, 34, 9078, 270, 87, 860, 31805, 16332, 7499, 31806, 52431, 52432, 36, 8869, 45, 990, 5302, 1707, 3737, 36, 10943, 148, 11985, 9663, 608, 36, 11253, 78, 11, 52433, 27599, 207, 628, 5610, 105, 97, 14275, 991, 127, 3, 7051, 508, 10634, 110, 789, 36, 860, 563, 96, 52434, 1391, 2215, 36, 99, 38744, 194, 52435, 52436, 52437, 22530, 10941, 36, 547, 955, 52438, 5042, 52439, 31807, 1264, 12, 22, 8068, 36, 45, 3002, 5682, 495, 1535, 306, 2698, 3262, 44, 104, 101, 8069, 2815, 9453, 294, 40, 123, 52440, 241, 2318, 399, 12397, 4158, 212, 96, 357, 74, 8210, 1300, 860, 357, 3178, 860, 508, 24662, 714, 3016, 631, 4238, 59, 1383, 27595, 284, 2352, 36, 69, 110, 399, 13229, 59, 1324, 80, 3475, 452, 1609, 6654, 52441, 571, 357, 1117, 6966, 357, 9248, 52442, 8535, 31808, 52443, 7053, 645, 52444, 399, 14279, 344, 27600, 2533, 105, 7941, 563, 858, 9664, 1848, 15, 1521, 52445, 645, 7497, 806, 6867, 3387, 12804, 36, 10944, 96, 2298, 11254, 495, 380, 10115, 3, 13, 699, 19326, 4238, 154, 1848, 15, 1521, 36, 10941, 52446, 1403, 24667, 3027, 212, 24653, 2830, 276, 120, 229, 11, 20751, 102, 2677, 16333, 20751, 52447, 52448, 52449, 52450, 52451, 401, 1535, 563, 52452, 27601, 1535, 1654, 575, 399, 15555, 2114, 569, 2983, 357, 9249, 208, 12, 22, 36, 837, 2, 16, 128, 116, 7054, 569, 11986, 8694, 4117, 212, 27602, 36, 10635, 6966, 53, 111, 7049, 1521, 281, 9, 1521, 6, 52453, 15559, 2351, 169, 24668, 14905, 31809, 14280, 357, 399, 52454, 5861, 16, 126, 276, 2591, 212, 710, 9, 2, 23, 9453, 184, 710, 387, 149, 9453, 7049, 1521, 2, 110, 36, 1473, 15, 284, 619, 1300, 38745, 357, 2, 646, 1300, 12805, 10356, 3209, 495, 38746, 96, 8870, 3, 52455, 110, 22531, 12801, 9250, 14275, 548, 7154, 121, 1300, 10356, 496, 38747, 27603, 36, 1, 10359, 161, 36, 646, 1391, 8534, 24669, 110, 860, 45, 17198, 2216, 16334, 1127, 3628, 6866, 903, 121, 212, 87, 3937, 27604, 24670, 657, 1, 3862, 9249, 14280, 3121, 21, 124, 40, 5499, 2592, 2349, 10118, 1127, 24671, 1300, 27605, 357, 52456, 3476, 399, 484, 38743, 5438, 52457, 52458, 1391, 45, 17194, 38748, 1428, 135, 15555, 2351, 36, 17199, 530, 334, 15560, 155, 70, 1, 1459, 128, 357, 8871, 36, 7787, 92, 3045, 53, 2953, 399, 860, 29, 14281, 939, 52459, 860, 2041, 285, 52460, 22532, 5751, 128, 285, 381, 36, 1160, 60, 2, 16335, 953, 899, 3084, 10360, 3779, 8, 44, 52461, 128, 409, 2659, 52462, 1014, 2, 7049, 476, 90, 56, 1521, 52463, 13728, 40, 256, 793, 22533, 3085, 104, 4238, 535, 154, 1300, 10356, 496, 140, 4792, 3084, 1058, 795, 33, 5196, 25, 710, 4271, 2533, 105, 18134, 860, 16336, 27595, 284, 1928, 49, 24672, 96, 135, 201, 255, 27606, 19321, 9882, 311, 6485, 14275, 52464, 2042, 4060, 36, 2162, 547, 496, 473, 469, 31810, 284, 1126, 54, 49, 7500, 36, 96, 1391, 1300, 36, 399, 147, 2, 311, 11255, 120, 24673, 10356, 120, 357, 66, 52465, 638, 148, 6088, 1194, 21, 38727, 35, 132, 4476, 52466, 1723, 14910, 1122, 96, 291, 45, 17200, 364, 2000, 176, 2138, 11981, 22, 12, 3971, 399, 20752, 52467, 12398, 280, 1300, 10945, 584, 610, 495, 24674, 380, 10634, 789, 31811, 1535, 563, 955, 31812, 45, 1614, 52468, 357, 121, 52469, 637, 259, 27602, 5611, 25, 60, 382, 52470, 96, 4793, 3863, 2, 110, 36, 1171, 1198, 472, 70, 1, 31813, 36, 17201, 96, 1147, 19, 1521, 2, 6, 104, 5862, 497, 692, 52471, 484, 8872, 4654, 484, 20753, 27607, 132, 24675, 497, 757, 17202, 1581, 8536, 10356, 31792, 1300, 31814, 10119, 52472, 1521, 1521, 7049, 991, 12, 29, 828, 36, 15555, 3914, 10636, 1300, 10356, 1, 769, 3107, 30, 3344, 173, 1217, 2042, 11982, 280, 547, 11615, 1300, 496, 10356, 3147, 51, 2299, 1300, 357, 110, 52473, 5376, 980, 495, 110, 10115, 3704, 6559, 923, 38749, 52474, 3453, 1300, 496, 10356, 52475, 52476, 413, 6401, 105, 422, 34, 96, 1225, 158, 420, 52477, 428, 96, 16336, 38750, 52478, 52479, 20754, 31815, 31816, 5144, 29, 3705, 19327, 60, 23, 9251, 1, 20755, 7269, 3017, 1300, 357, 495, 52480, 110, 25, 52481, 282, 6, 1122, 121, 10361, 5683, 36, 38751, 6486, 128, 27608, 54, 52482, 8211, 1521, 2, 514, 1267, 88, 52483, 19324, 17195, 860, 1199, 38752, 276, 1819, 27609, 4390, 6487, 69, 7157, 259, 36, 803, 15, 1521, 133, 1521, 1622, 73, 102, 402, 495, 38746, 6089, 52484, 52485, 3830, 52486, 22534, 19328, 344, 288, 52487, 165, 14911, 406, 1535, 563, 27610, 52488, 1391, 38753, 52489, 52490, 52491, 399, 821, 267, 6484, 110, 10941, 126, 36, 11616, 880, 23, 34, 2830, 24676, 212, 99, 2556, 52492, 844, 1694, 36, 563, 1535, 212, 8537, 36, 2227, 83, 36, 2351, 837, 11617, 36, 66, 497, 638, 120, 212, 52493, 87, 110, 299, 2, 110, 99, 560, 96, 2300, 52494, 2457, 8363, 19329, 4272, 860, 7497, 7386, 4239, 5, 38, 20, 6005, 550, 2504, 31817, 6868, 3605, 52495, 52496, 22530, 563, 2859, 13729, 389, 2148, 66, 153, 87, 521, 15561, 31818, 96, 27611, 14905, 406, 17194, 52497, 12399, 10362, 36, 1087, 25, 52498, 2628, 343, 278, 103, 52499, 17194, 45, 3830, 7942, 11982, 8070, 696, 29, 148, 28, 13730, 17203, 39, 120, 11984, 12805, 909, 57, 1521, 127, 1444, 319, 842, 495, 380, 38754, 6161, 1509, 13230, 31819, 2285, 474, 110, 52500, 27612, 105, 13731, 1, 14275, 474, 36, 105, 1974, 6401, 20756, 135, 255, 52501, 399, 15555, 110, 5612, 1391, 8071, 12, 357, 36, 52502, 14905, 1472, 110, 399, 2860, 531, 18, 630, 13732, 130, 86, 739, 49, 36, 52503, 1300, 36, 1046, 547, 161, 155, 1, 288, 2374, 2816, 1217, 11982, 299, 25, 891, 59, 21, 30, 16337, 52504, 3147, 51, 530, 4, 52505, 99, 8364, 36, 508, 153, 4311, 380, 96, 120, 1402, 52506, 3831, 128, 103, 38755, 994, 135, 10946, 548, 31792, 1300, 10637, 22535, 1074, 101, 495, 110, 52507, 806, 381, 6248, 126, 128, 18, 120, 1346, 899, 860, 25, 110, 4988, 547, 829, 2, 1763, 991, 2440, 1217, 1100, 36, 18140, 31820, 17204, 110, 14275, 1898, 208, 52508, 344, 288, 10363, 8365, 38756, 1300, 10115, 36, 6, 399, 3411, 128, 1508, 22536, 36, 844, 1975, 36, 74, 7385, 20757, 2257, 837, 11617, 31821, 1537, 2286, 3972, 124, 2490, 34, 10947, 36, 2041, 19, 3454, 4991, 24677, 23, 56, 10360, 27602, 10120, 434, 1, 1960, 52509, 530, 15, 111, 24657, 2043, 2440, 1217, 1100, 36, 3210, 52510, 96, 495, 380, 15562, 2769, 92, 146, 2458, 406, 120, 52511, 96, 14280, 20758, 344, 6970, 4, 9079, 699, 24678, 284, 130, 821, 110, 18, 2349, 13231, 11618, 9880, 2056, 121, 1118, 52512, 8366, 307, 131, 2699, 7940, 3084, 547, 1615, 941, 399, 36, 8873, 96, 41, 36, 674, 495, 110, 52513, 497, 757, 2838, 69, 1521, 7049, 52514, 1521, 7049, 52515, 36, 4691, 9880, 1211, 2427, 83, 11, 2227, 11987, 4, 1521, 2041, 110, 357, 4944, 19330, 14912, 2041, 110, 357, 874, 171, 12799, 1300, 52516, 3247, 3832, 1521, 8212, 1819, 165, 5500, 14913, 29, 774, 137, 9, 6006, 1428, 52517, 548, 188, 10638, 1117, 31822, 270, 2075, 450, 4393, 1217, 148, 6088, 1194, 31823, 1785, 24679, 27600, 2062, 2, 11256, 2325, 36, 22537, 373, 134, 36, 1391, 473, 105, 11988, 97, 301, 4118, 2606, 52518, 719, 18141, 36, 3190, 1391, 12400, 357, 860, 1066, 68, 2063, 495, 110, 52519, 9, 2, 31824, 15563, 1217, 399, 1538, 547, 2907, 11256, 2591, 1202, 860, 357, 24680, 1820, 52520, 17194, 27602, 1346, 36, 4989, 45, 96, 36, 38757, 161, 20759, 1, 8538, 1325, 7270, 36, 127, 14275, 702, 1022, 1394, 34, 83, 1559, 211, 1364, 178, 1589, 97, 4312, 15555, 128, 357, 31825, 6869, 31826, 164, 1300, 357, 1055, 14275, 55, 6969, 80, 103, 52521, 24681, 10, 161, 38758, 1, 1492, 120, 27613, 52522, 6655, 229, 103, 92, 14282, 13, 5303, 149, 301, 29, 34, 66, 1072, 88, 241, 130, 2318, 3, 127, 36, 1151, 357, 31827, 96, 311, 16331, 1073, 9883, 699, 224, 127, 18142, 2125, 1878, 24662, 18134, 860, 52523, 284, 11257, 2872, 66, 389, 1300, 10356, 2504, 140, 1203, 10115, 8072, 101, 1521, 9079, 6867, 3833, 773, 357, 329, 45, 1391, 87, 7154, 13722, 637, 120, 1492, 2205, 13722, 7154, 1007, 66, 8, 1119, 1, 2491, 48, 1949, 101, 9664, 3474, 103, 2908, 1, 15564, 140, 25, 36, 27614, 3248, 617, 1165, 3973, 29, 12806, 1711, 3864, 38759, 38760, 860, 9252, 16336, 52524, 126, 2492, 11258, 7266, 406, 165, 15555, 164, 111, 52525, 1150, 103, 52526, 13733, 357, 547, 36, 5609, 3552, 10639, 7055, 859, 11259, 2459, 14914, 50, 129, 18137, 860, 409, 910, 165, 52527, 3606, 1056, 8, 547, 5609, 1758, 18, 16326, 27605, 38761, 38762, 399, 495, 110, 52528, 5377, 52529, 18143, 11981, 120, 216, 36, 1521, 16330, 1, 161, 52530, 24657, 357, 10943, 1166, 147, 128, 399, 24682, 8695, 1300, 13232, 357, 245, 11, 98, 285, 52531, 3108, 123, 20760, 24683, 56, 15555, 547, 68, 2126, 993, 52532, 52533, 123, 21, 24684, 694, 38763, 256, 331, 221, 126, 946, 2660, 196, 270, 6967, 844, 36, 18, 56, 88, 23, 49, 158, 844, 110, 96, 399, 2349, 3938, 399, 24685, 6656, 52534, 34, 8, 50, 24686, 5556, 7154, 2557, 1007, 1300, 53, 631, 4119, 18144, 399, 199, 494, 3475, 31828, 1929, 110, 12400, 52535, 38764, 38765, 128, 278, 24662, 18134, 860, 31829, 3572, 36, 103, 406, 15565, 36, 6162, 31830, 381, 36, 52536, 710, 516, 357, 10634, 6402, 52537, 52538, 165, 4, 991, 36, 86, 24687, 699, 148, 6088, 52539, 11618, 399, 20761, 22, 9253, 66, 495, 110, 10115, 837, 110, 10633, 7497, 110, 52540, 13734, 500, 357, 10640, 547, 31831, 923, 576, 2861, 123, 531, 23, 6966, 135, 860, 10356, 2504, 1300, 1508, 2360, 16338, 36, 31832, 31833, 34, 23, 13, 24688, 10948, 399, 2351, 3067, 284, 7784, 16339, 80, 1300, 52541, 10356, 8539, 1521, 127, 12805, 121, 96, 1127, 38764, 3068, 624, 547, 110, 147, 12801, 1147, 1073, 15566, 15567, 1535, 52542, 3086, 5557, 7788, 6, 2, 20762, 18134, 111, 255, 1022, 702, 981, 399, 4240, 27615, 249, 15555, 14280, 25, 7266, 12807, 2449, 66, 1119, 24657, 380, 106, 455, 284, 52543, 1568, 17205, 21, 428, 288, 9884, 31834, 15555, 130, 38762, 9885, 8538, 8874, 6006, 3211, 66, 13233, 389, 7497, 19322, 96, 806, 357, 31830, 6967, 14283, 158, 4439, 29, 759, 818, 388, 6560, 56, 96, 413, 3385, 7159, 243, 96, 18145, 1949, 2064, 36, 4, 36, 52544, 52545, 49, 31835, 12401, 547, 15555, 99, 103, 5684, 45, 474, 14275], [11260, 18146, 1522, 2, 33, 22538, 2, 821, 1487, 503, 19331, 312, 16340, 18146, 2173, 20763, 311, 39, 39, 2361, 336, 52547, 39, 1, 14284, 12402, 39, 1229, 646, 7160, 1820, 224, 292, 3998, 443, 410, 39, 10641, 1347, 10121, 10642, 1402, 106, 117, 930, 24689, 7160, 277, 2, 150, 239, 16341, 1030, 17206, 165, 259, 80, 1478, 18146, 10364, 778, 5043, 19332, 113, 2, 23, 9881, 1, 3673, 523, 60, 2, 52548, 63, 22539, 18147, 38766, 1119, 39, 503, 7943, 63, 57, 2909, 2, 39, 815, 15568, 2240, 5931, 39, 20764, 10356, 15569, 373, 6971, 3606, 2, 538, 1412, 90, 18, 3325, 16342, 39, 1616, 33, 2700, 30, 11619, 18, 2, 373, 23, 461, 1402, 1087, 52549, 1402, 117, 2, 6, 345, 18, 150, 915, 691, 56, 472, 7501, 2, 106, 4394, 39, 345, 18, 2782, 8540, 2, 1619, 632, 277, 887, 909, 52550, 37, 45, 2, 31, 23, 4, 2, 4159, 52551, 6090, 1, 16343, 18, 2, 410, 443, 8367, 2910, 314, 90, 23, 18, 2, 373, 10122, 39, 24690, 3780, 503, 31836, 39, 17207, 194, 810, 39, 10364, 10949, 52552, 7789, 7944, 38767, 322, 56, 39, 915, 7161, 915, 7161, 106, 2782, 165, 237, 6090, 52553, 352, 19, 2921, 23, 24691, 3706, 1022, 80, 199, 5863, 930, 4312, 117, 2, 235, 12403, 51, 150, 230, 1429, 38768, 277, 10950, 909, 22540, 60, 4692, 23, 11989, 8, 291, 2, 358, 195, 1062, 1759, 759, 2, 410, 2049, 2001, 224, 39, 16344, 1508, 9665, 2, 8696, 1430, 4477, 6488, 345, 2701, 503, 39, 1263, 2, 1478, 230, 1961, 24692, 6090, 1478, 462, 2, 106, 863, 277, 22541, 60, 27616, 345, 187, 11260, 38769, 3069, 174, 19333, 35, 2, 7644, 3915, 25, 45, 126, 3, 171, 37, 39, 1955, 9886, 1955, 39, 38770, 2, 31, 9454, 1263, 11620, 1, 619, 10123, 449, 352, 4313, 2711]]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 400000\n",
    "\n",
    "def build_dataset(sentences):\n",
    "    words = ''.join(sentences).split()\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    \n",
    "    unk_count = 0\n",
    "    sent_data = []\n",
    "    for sentence in sentences:\n",
    "        data = []\n",
    "        for word in sentence.split():\n",
    "            if word in dictionary:\n",
    "                index = dictionary[word]\n",
    "            else:\n",
    "                index = 0  # dictionary['UNK']\n",
    "                unk_count = unk_count + 1\n",
    "            data.append(index)\n",
    "        sent_data.append(data)\n",
    "    \n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return sent_data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(sentences_df_indexed['words'].tolist())\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:2])\n",
    "# del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810211\n"
     ]
    }
   ],
   "source": [
    "skip_window = 5\n",
    "instances = 0\n",
    "\n",
    "# Pad sentence with skip_windows\n",
    "for i in range(len(data)):\n",
    "    data[i] = [vocabulary_size]*skip_window+data[i]+[vocabulary_size]*skip_window\n",
    "\n",
    "# Check how many training samples that we get    \n",
    "for sentence  in data:\n",
    "    instances += len(sentence)-2*skip_window\n",
    "print(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = np.zeros((instances,skip_window*2+1),dtype=np.int32)\n",
    "labels = np.zeros((instances,1),dtype=np.int32)\n",
    "doc = np.zeros((instances,1),dtype=np.int32)\n",
    "\n",
    "k = 0\n",
    "for doc_id, sentence  in enumerate(data):\n",
    "    for i in range(skip_window, len(sentence)-skip_window):\n",
    "        context[k] = sentence[i-skip_window:i+skip_window+1] # Get surrounding words\n",
    "        labels[k] = sentence[i] # Get target variable\n",
    "        doc[k] = doc_id\n",
    "        k += 1\n",
    "        \n",
    "context = np.delete(context,skip_window,1) # delete the middle word        \n",
    "        \n",
    "shuffle_idx = np.random.permutation(k)\n",
    "labels = labels[shuffle_idx]\n",
    "doc = doc[shuffle_idx]\n",
    "context = context[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e83d95f4a36b>:41: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "context_window = 2*skip_window\n",
    "embedding_size = 50 # Dimension of the embedding vector.\n",
    "softmax_width = embedding_size # +embedding_size2+embedding_size3\n",
    "num_sampled = 5 # Number of negative examples to sample.\n",
    "sum_ids = np.repeat(np.arange(batch_size),context_window)\n",
    "\n",
    "len_docs = len(data)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(): # , tf.device('/cpu:0')\n",
    "    # Input data.\n",
    "    train_word_dataset = tf.placeholder(tf.int32, shape=[batch_size*context_window])\n",
    "    train_doc_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "    segment_ids = tf.constant(sum_ids, dtype=tf.int32)\n",
    "\n",
    "    word_embeddings = tf.Variable(tf.random_uniform([vocabulary_size,embedding_size],-1.0,1.0))\n",
    "    word_embeddings = tf.concat([word_embeddings,tf.zeros((1,embedding_size))],0)\n",
    "    doc_embeddings = tf.Variable(tf.random_uniform([len_docs,embedding_size],-1.0,1.0))\n",
    "\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, softmax_width],\n",
    "                             stddev=1.0 / np.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Model.\n",
    "    # Look up embeddings for inputs.\n",
    "    embed_words = tf.segment_mean(tf.nn.embedding_lookup(word_embeddings, train_word_dataset),segment_ids)\n",
    "    embed_docs = tf.nn.embedding_lookup(doc_embeddings, train_doc_dataset)\n",
    "    embed = (embed_words+embed_docs)/2.0#+embed_hash+embed_users\n",
    "\n",
    "    # Compute the softmax loss, using a sample of the negative labels each time.\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(softmax_weights, softmax_biases, train_labels, \n",
    "                                         embed, num_sampled, vocabulary_size))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.AdagradOptimizer(0.5).minimize(loss)\n",
    "        \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(doc_embeddings), 1, keep_dims=True))\n",
    "    normalized_doc_embeddings = doc_embeddings / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################\n",
    "# Chunk the data to be passed into the tensorflow Model\n",
    "###########################\n",
    "data_idx = 0\n",
    "def generate_batch(batch_size):\n",
    "    global data_idx\n",
    "\n",
    "    if data_idx+batch_size<instances:\n",
    "        batch_labels = labels[data_idx:data_idx+batch_size]\n",
    "        batch_doc_data = doc[data_idx:data_idx+batch_size]\n",
    "        batch_word_data = context[data_idx:data_idx+batch_size]\n",
    "        data_idx += batch_size\n",
    "    else:\n",
    "        overlay = batch_size - (instances-data_idx)\n",
    "        batch_labels = np.vstack([labels[data_idx:instances],labels[:overlay]])\n",
    "        batch_doc_data = np.vstack([doc[data_idx:instances],doc[:overlay]])\n",
    "        batch_word_data = np.vstack([context[data_idx:instances],context[:overlay]])\n",
    "        data_idx = overlay\n",
    "    batch_word_data = np.reshape(batch_word_data,(-1,1))\n",
    "\n",
    "    return batch_labels, batch_word_data, batch_doc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "INFO:tensorflow:Restoring parameters from ./model/doc2vec_model\n"
     ]
    }
   ],
   "source": [
    "num_steps = 200001\n",
    "step_delta = int(num_steps/20)\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    average_loss = 0\n",
    "#     for step in range(num_steps):\n",
    "#         batch_labels, batch_word_data, batch_doc_data\\\n",
    "#         = generate_batch(batch_size)\n",
    "#         feed_dict = {train_word_dataset : np.squeeze(batch_word_data),\n",
    "#                      train_doc_dataset : np.squeeze(batch_doc_data),\n",
    "#                      train_labels : batch_labels}\n",
    "#         _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "#         average_loss += l\n",
    "#         if step % step_delta == 0:\n",
    "#             if step > 0:\n",
    "#                 average_loss = average_loss / step_delta\n",
    "#             # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "#             print('Average loss at step %d: %f' % (step, average_loss))\n",
    "#             average_loss = 0\n",
    "#     save_path = tf.train.Saver().save(session, \"./model/doc2vec_model\")    \n",
    "    #restore model\n",
    "    tf.train.Saver().restore(session, \"./model/doc2vec_model\")  \n",
    "    \n",
    "    # Get the weights to save for later\n",
    "    final_word_embeddings = word_embeddings.eval()\n",
    "    final_word_embeddings_out = softmax_weights.eval()\n",
    "    final_doc_embeddings = normalized_doc_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(user_id, size):\n",
    "    if user_id in sentences_df_indexed.index:\n",
    "        user_index = sentences_df_indexed.loc[user_id]['index']\n",
    "        dist = final_doc_embeddings.dot(final_doc_embeddings[user_index][:,None])\n",
    "        closest_doc = np.argsort(dist,axis=0)[-size:][::-1]\n",
    "        furthest_doc = np.argsort(dist,axis=0)[0][::-1]\n",
    "\n",
    "        result = []\n",
    "        for idx, item in enumerate(closest_doc):\n",
    "            user = sentences[closest_doc[idx][0]].split()[0]\n",
    "            dist_value = dist[item][0][0]\n",
    "            result.append([user, dist_value])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#a0df5bd0e5a5bbc28b87f8c64462667c', 0.9999999],\n",
       " ['@realplan1', 0.67656094],\n",
       " ['@aviationusa', 0.64471817],\n",
       " ['#c92cec1183fbea36203d8390cb9fdf26', 0.62998474],\n",
       " ['@sanjang', 0.6293229],\n",
       " ['@minjungchae', 0.62754667],\n",
       " ['@withalice', 0.625159],\n",
       " ['@8full', 0.6096053],\n",
       " ['@andrewlee', 0.6068463],\n",
       " ['@gyyh', 0.60485464],\n",
       " ['@uppity', 0.60338295],\n",
       " ['@omoggy', 0.60293984],\n",
       " ['@kyoungjinpark', 0.59972274],\n",
       " ['@moonwindtre', 0.59952426],\n",
       " ['@havaqquq', 0.59934634],\n",
       " ['@kimyuree', 0.5964108],\n",
       " ['@tedwortworth', 0.5951053],\n",
       " ['@shinyoungpa', 0.59327114],\n",
       " ['@beforebossy', 0.5925418],\n",
       " ['@nowandong', 0.5906514]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('#a0df5bd0e5a5bbc28b87f8c64462667c', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#87a6479c91e4276374378f1d28eb307c', 1.0000002],\n",
       " ['#3fe808daf9829225707fb77739858636', 0.7260888],\n",
       " ['@jh2019', 0.59609675],\n",
       " ['@dkfdkfdl', 0.57348394],\n",
       " ['@skyline1019', 0.54642665],\n",
       " ['@pjsprau', 0.53523934],\n",
       " ['@kjeun1', 0.5347438],\n",
       " ['@iamsunha', 0.52899516],\n",
       " ['@peterhbkim', 0.51751715],\n",
       " ['@cyprusssctbm', 0.5175168]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('#87a6479c91e4276374378f1d28eb307c', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def similar(user_id, writer_id):\n",
    "    if user_id in sentences_df_indexed.index and writer_id in sentences_df_indexed.index:\n",
    "        user_index = sentences_df_indexed.loc[user_id]['index']\n",
    "        writer_index = sentences_df_indexed.loc[writer_id]['index']\n",
    "        dist= spatial.distance.cosine(final_doc_embeddings[user_index], final_doc_embeddings[writer_index])\n",
    "        print('{} - {} : {}'.format(user_id, writer_id, dist))\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#d6866a498157771069fdf15361cb012b - @seochogirl : 0.9860673602670431\n",
      "#d6866a498157771069fdf15361cb012b - @brunch : 0.8184942752122879\n",
      "#87a6479c91e4276374378f1d28eb307c - @begintalk : 0.9809975810348988\n",
      "#87a6479c91e4276374378f1d28eb307c - @tnrud572 : 0.7063705027103424\n",
      "#a0df5bd0e5a5bbc28b87f8c64462667c - @kimmh12728xrf : 0.7746954560279846\n",
      "#a0df5bd0e5a5bbc28b87f8c64462667c - @brunch : 0.6628093719482422\n",
      "#ec0fb734ba02a29c62c64e7ac7a8f13e - @sethahn : 0.919483095407486\n",
      "#ec0fb734ba02a29c62c64e7ac7a8f13e - @nomadesk : 1.0463214404881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0463214404881"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar('#d6866a498157771069fdf15361cb012b', '@seochogirl')\n",
    "similar('#d6866a498157771069fdf15361cb012b', '@brunch')\n",
    "similar('#87a6479c91e4276374378f1d28eb307c', '@begintalk')\n",
    "similar('#87a6479c91e4276374378f1d28eb307c', '@tnrud572')\n",
    "similar('#a0df5bd0e5a5bbc28b87f8c64462667c', '@kimmh12728xrf')\n",
    "similar('#a0df5bd0e5a5bbc28b87f8c64462667c', '@brunch')\n",
    "similar('#ec0fb734ba02a29c62c64e7ac7a8f13e', '@sethahn')\n",
    "similar('#ec0fb734ba02a29c62c64e7ac7a8f13e', '@nomadesk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
